id,sentence
3,"The feature set was previously shown to work well in a supervised learning setting, using known english verb classes."
5,"We investigate various approaches to feature selection, using both unsupervised and semi-supervised methods, comparing the results to subsets of features manually chosen according to linguistic properties."
7,"However, the semi- supervised approach (using a seed set of sample verbs) overall outperforms not only the full set of features, but the hand-selected features as well."
10,"A number of supervised learning approaches have extracted such information about verbs from corpora, including their argument roles (gildea and jurafsky, 2002), selectional preferences (resnik, 1996), and lexical semantic classification (i.e., grouping verbs according to their argument structure properties) (dorr and jones, 1996; lapata and brew, 1999; merlo and stevenson, 2001; joanis and stevenson, 2003)."
12,"We focus here on extending the applicability of unsupervised methods, as in (schulte im walde and brew, 2002; stevenson and merlo, 1999), to the lexical semantic classification of verbs."
14,"As such, they serve as a means for organizing complex knowledge about verbs in a computational lexicon (kipper et al., 2000)."
17,It is also necessary to consider the probable lack of sophisticated grammars or text processing tools for extracting accurate features.
18,"We have previously shown that a broad set of 220 noisy features performs well in supervised verb classification (joanis and stevenson, 2003)."
19,"In contrast to merlo and stevenson (2001), we confirmed that a set of general features can be successfully used, without the need for manually determining the relevant features for distinguishing particular classes (cf."
20,"Dorr and jones, 1996; schulte im walde and brew, 2002)."
23,"However, a general feature space means that most features will be irrelevant to any given verb discrimination task."
28,"In this paper, we report results on several feature selection approaches to the problem: manual selection (based on linguistic knowledge), unsupervised selection (based on an entropy measure among the features, dash et al., 1997), and a semi- supervised approach (in which seed verbs are used to train a supervised learner, from which we extract the useful features)."
35,"Like others, we have assumed lexical semantic classes of verbs as defined in levin (1993) (hereafter levin), which have served as a gold standard in computational linguistics research (dorr and jones, 1996; kipper et al., 2000; merlo and stevenson, 2001; schulte im walde and brew, 2002)."
50,"Currently, our only such feature is an extension of the animacy feature of merlo and stevenson (2001)."
52,We use the same classes and example verbs as in the supervised experiments of joanis and stevenson (2003) to enable a comparison between the performance of the unsupervised and supervised methods.
81,These three classes also assign the same semantic roles but differ in prepositional alternants.
82,"Note, however, that the options for spray/load verbs overlap with those of the other two types of verbs."
87,(note that the object drop verbs are a superset of the benefactives above.)
89,"Dorr and jones, 1996)."
114,"We then replaced 10 of the 260 verbs (4%) to enable us to have representative seed verbs for certain classes in our semi-supervised experiments (e.g., so that we could include wipe as a seed verb for the wipe verbs, and fill for the fill verbs)."
119,"We used the chunker (partial parser) of abney (1991) to preprocess the corpus, which (noisily) determines the np subject and direct object of a verb, as well as the pps potentially associated with it."
120,"Indirect objects are identified by a less sophisticated (and even noisier) method, simply assuming that two consecutive nps after the verb constitute a double object frame."
123,"We used the hierarchical clustering command in matlab, which implements bottom-up agglomerative clustering, for all our unsupervised experiments."
124,"In performing hierarchical clustering, both a vector distance measure and a cluster distance (“linkage”) measure are specified."
128,"To explore this, we can induce any number of clusters by making a cut at a particular level in the clustering hierarchy."
130,"However, we did experiment with (as in strehl et al., 2000), and found that performance was generally better (even on our measure, described below, that discounts oversplitting)."
136,"Then accuracy has the standard definition:2 2 is equivalent to the weighted mean precision of the clusters, weighted according to cluster size."
139,"To calculate a random baseline, we evaluated 10,000 random clusterings with the same number of verbs and classes as in each of our experimental tasks."
140,"Because the achieved depends on the precise size of clusters, we calculated mean over the best scenario (with equal-sized clusters), yielding a conservative estimate (i.e., an upper bound) of the baseline."
141,These figures are reported with our results in table 2 below.
143,"Our second measure, the adjusted rand measure used by schulte im walde (2003), instead gives a measure of how consistent the given clustering is overall with respect to the gold standard classification."
144,"The formula is as follows (hubert and arabie, 1985): where is the entry in the contingency table between the classification and the clustering, counting the size of the intersection of class and cluster"
151,"Our final measure gives an indication of the overall goodness of the clusters purely in terms of their separation of the data, without number of clusters equal to the number of verbs."
152,"However, since we fix our number of clusters to the number of classes, the measure remains informative."
164,"We use , the mean of the silhouette measure from matlab, which measures how distant a data point is from other clusters."
174,"However, it gives important information about the quality of a clustering: the other measures being equal, a clustering with a higher value indicates tighter and more separated clusters, suggesting stronger inherent patterns in the data."
181,We use this baseline in calculating reductions in error rate of
184,"The first subcolumn (full) under each of the three clustering evaluation measures in table 2 shows the results using the full set of features (i.e., no feature selection)."
188,"Following joanis and stevenson (2003), for each class, we systematically identified the subset of features 4 these results differ slightly from those reported in joanis and stevenson (2003), because of our slight changes in verb sets, discussed in section 3.2."
197,"The results for these feature sets in clustering are given in the second subcolumn (ling) under each of the , , and measures in table 2."
201,"Moreover, the value for the manually selected features is almost always very much higher than that of the full feature set, indicating that the subset of features is more focused on the properties that lead to a better separation of the data."
203,"However, it is important to find a method that does not depend on having an existing classification, since we are interested in applying the approach when such a classification does not exist."
214,Unsupervised methods such as dash et al.’s (1997) are appealing because they require no knowledge external to the data.
218,"To model this kind of approach, we selected a sample of five seed verbs from each class."
221,"For each experimental task, we ran our supervised table 3: feature counts for ling and seed feature sets."
224,"Each clustering experiment used the full set of 20 verbs per class; i.e., seed verbs were included, following our proposed model of guided verb class discovery.5 the results using these feature sets are shown in the third subcolumn (seed) under our three evaluation measures in table 2."
232,"In our clustering experiments, we find that smaller subsets of features generally perform better than the full set of features."
236,"We calculated the mi of each feature with respect to the classification of the seed verbs, and computed clusterings using the features above a certain mi threshold."
242,"We also find that our semi-supervised method (seed) is linguistically plausible, and performs as well as or better than features manually determined based on linguistic knowledge (ling)."
244,"To answer this, we ran experiments using 50 different randomly selected seed verb sets for each class."
247,"This is promising for our method, as it shows that the precise selection of a seed set of verbs is not crucial to the success of the semi-supervised approach."
248,"Using the same measure as ours, stevenson and merlo (1999) achieved performance in clustering very close to that of their supervised classification."
250,"Our feature set is essentially a generalization of theirs, but in scaling up the feature space to be useful across english verb classes in general, we necessarily face a dimensionality problem that did not arise in their research."
251,"Schulte im walde and brew (2002) and schulte im walde (2003), on the other hand, use a larger set of features intended to be useful for a broad number of classes, as in our work."
252,"The scores of schulte im walde (2003) range from .09 to .18, while ours range from .02 to .34, with a mean of .17 across all tasks."
253,"However, schulte im walde’s features rely on accurate subcategorization statistics, and her experiments include a much larger set of classes (around 40), each with a much smaller number of verbs (average around 4)."
257,"We have explored manual, unsupervised, and semi- supervised methods for feature selection in a clustering approach for verb class discovery."
258,"We find that manual selection of a subset of features based on the known classification performs better than using a full set of noisy features, demonstrating the potential benefit of feature selection in our task."
259,"An unsupervised method we tried (dash et al., 1997) did not prove useful, because of the problem of having no consistent threshold for feature inclusion."
260,"We instead proposed a semi-supervised method in which a seed set of verbs is chosen for training a supervised classifier, from which the useful features are extracted for use in clustering."
262,"Furthermore, the method is relatively insensitive to the precise makeup of the selected seed set."
265,"Furthermore, we might question the clustering approach itself, in the context of verb class discovery."
266,"Rather than trying to separate a set of new verbs into coherent clusters, we suggest that it may be useful to perform a nearest-neighbour type of classification using a seed set, asking for each new verb “is it like these or not?” in some ways our current clustering task is too easy, because all of the verbs are from one of the target classes."
